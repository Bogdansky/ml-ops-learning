from pathlib import Path
import json
import argparse

import numpy as np
from sentence_transformers import SentenceTransformer
import faiss


def load_embeddings(emb_path: Path) -> np.ndarray:
    if not emb_path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {emb_path}")
    embeddings = np.load(emb_path)

    if embeddings.ndim != 2:
        raise ValueError(f"–û–∂–∏–¥–∞–ª–∞—Å—å –º–∞—Ç—Ä–∏—Ü–∞ 2D, –∞ –Ω–µ —Ñ–æ—Ä–º–∞ {embeddings.shape}")

    # FAISS –ª—é–±–∏—Ç float32
    if embeddings.dtype != np.float32:
        embeddings = embeddings.astype(np.float32)

    return embeddings


def load_meta(meta_path: Path) -> list[dict]:
    if not meta_path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {meta_path}")
    data = json.loads(meta_path.read_text(encoding="utf-8"))
    if not isinstance(data, list):
        raise ValueError("–û–∂–∏–¥–∞–ª—Å—è —Å–ø–∏—Å–æ–∫ –≤ chunks_meta.json")
    return data


def build_model() -> SentenceTransformer:
    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    print(f"‚ñ∂ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {model_name}")
    model = SentenceTransformer(model_name)
    return model


def build_faiss_index(embeddings: np.ndarray) -> faiss.Index:
    """
    –°—Ç—Ä–æ–∏–º —Ç–æ—á–Ω—ã–π FAISS-–∏–Ω–¥–µ–∫—Å –ø–æ —Å–∫–∞–ª—è—Ä–Ω–æ–º—É –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—é (inner product).
    –¢–∞–∫ –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —É –Ω–∞—Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã, inner product = cosine similarity.
    """
    num_vecs, dim = embeddings.shape
    print(f"‚ñ∂ –°—Ç—Ä–æ—é FAISS IndexFlatIP, num_vecs={num_vecs}, dim={dim}")

    # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å
    index = faiss.IndexFlatIP(dim)

    # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–∞ –≤ –∏–Ω–¥–µ–∫—Å
    index.add(embeddings)

    print(f"‚ñ∂ –í –∏–Ω–¥–µ–∫—Å –¥–æ–±–∞–≤–ª–µ–Ω–æ {index.ntotal} –≤–µ–∫—Ç–æ—Ä–æ–≤")
    return index


def search_faiss(
    query: str,
    model: SentenceTransformer,
    index: faiss.Index,
    embeddings: np.ndarray,
    meta: list[dict],
    top_k: int = 3,
):
    # –°—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
    query_vec = model.encode(
        [query],
        convert_to_numpy=True,
        normalize_embeddings=True,  # —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ embed_chunks.py
    )[0].astype(np.float32)

    # –ü—Ä–∏–≤–æ–¥–∏–º —Ñ–æ—Ä–º—É –∫ (1, dim), –∫–∞–∫ –ª—é–±–∏—Ç FAISS
    query_vec = np.expand_dims(query_vec, axis=0)

    # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–µ
    # distances shape: (1, top_k)
    # indices shape:   (1, top_k)
    distances, indices = index.search(query_vec, min(top_k, index.ntotal))

    idxs = indices[0]
    scores = distances[0]

    results = []
    for rank, (idx, score) in enumerate(zip(idxs, scores), start=1):
        idx = int(idx)
        if idx < 0:
            continue
        chunk_info = meta[idx]
        results.append(
            {
                "rank": rank,
                "score": float(score),
                "chunk_id": chunk_info.get("chunk_id"),
                "text": chunk_info.get("text", ""),
            }
        )
    return results


def pretty_print_results(results: list[dict], max_chars: int = 400):
    if not results:
        print("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    print("\n========= –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê (FAISS) =========")
    for r in results:
        text = r["text"].replace("\n", " ")
        if len(text) > max_chars:
            text_preview = text[:max_chars].rstrip() + "..."
        else:
            text_preview = text

        print(f"\n#{r['rank']}  (score={r['score']:.4f}, chunk_id={r['chunk_id']})")
        print(text_preview)
    print("=============================================\n")


def main():
    parser = argparse.ArgumentParser(description="–ü–æ–∏—Å–∫ –ø–æ —á–∞–Ω–∫–∞–º —Å –ø–æ–º–æ—â—å—é FAISS")
    parser.add_argument(
        "--embeddings",
        type=str,
        default="embeddings.npy",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ (.npy)",
    )
    parser.add_argument(
        "--meta",
        type=str,
        default="chunks_meta.json",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–æ —á–∞–Ω–∫–∞–º (.json)",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=3,
        help="–°–∫–æ–ª—å–∫–æ –±–ª–∏–∂–∞–π—à–∏—Ö —á–∞–Ω–∫–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å",
    )

    args = parser.parse_args()

    emb_path = Path(args.embeddings)
    meta_path = Path(args.meta)

    print("‚ñ∂ –ó–∞–≥—Ä—É–∂–∞—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∏...")
    embeddings = load_embeddings(emb_path)
    print(f"–§–æ—Ä–º–∞ –º–∞—Ç—Ä–∏—Ü—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embeddings.shape}")

    print("‚ñ∂ –ó–∞–≥—Ä—É–∂–∞—é –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ —á–∞–Ω–∫–∞–º...")
    meta = load_meta(meta_path)
    print(f"–ß–∞–Ω–∫–æ–≤ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {len(meta)}")

    if embeddings.shape[0] != len(meta):
        raise ValueError(
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ({embeddings.shape[0]}) "
            f"–Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —á–∞–Ω–∫–æ–≤ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ({len(meta)})"
        )

    # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
    # –¢–∞–º, –≥–¥–µ –Ω–æ—Ä–º–∞ > 0, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    mask = norms.squeeze() > 0
    embeddings[mask] = embeddings[mask] / norms[mask]

    model = build_model()
    index = build_faiss_index(embeddings)

    print("\n–ì–æ—Ç–æ–≤–æ. –ú–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å (FAISS).")
    print('–í–≤–µ–¥–∏ –∑–∞–ø—Ä–æ—Å –∏ –Ω–∞–∂–º–∏ Enter. –î–ª—è –≤—ã—Ö–æ–¥–∞ –≤–≤–µ–¥–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –∏–ª–∏ "q".\n')

    while True:
        try:
            query = input("üîé –ó–∞–ø—Ä–æ—Å: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n–í—ã—Ö–æ–¥.")
            break

        if not query or query.lower() in {"q", "quit", "exit"}:
            print("–í—ã—Ö–æ–¥.")
            break

        results = search_faiss(
            query=query,
            model=model,
            index=index,
            embeddings=embeddings,
            meta=meta,
            top_k=args.top_k,
        )
        pretty_print_results(results)


if __name__ == "__main__":
    main()
